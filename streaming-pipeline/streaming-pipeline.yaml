---
apiVersion: v1
kind: Namespace
metadata:
  name: streaming-pipeline
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: root-ca
  namespace: streaming-pipeline
spec:
  selfSigned: {}
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: root-ca-cert
  namespace: streaming-pipeline
spec:
  secretName: root-ca-key-pair
  duration: 87600h # 10 years
  renewBefore: 8760h # 1 year
  isCA: true
  commonName: root-ca
  issuerRef:
    name: root-ca
    kind: ClusterIssuer
---
## Optional intermediate CA ##
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: intermediate-ca
  namespace: streaming-pipeline
spec:
  ca:
    secretName: root-ca-key-pair
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: intermediate-ca-cert
  namespace: streaming-pipeline
spec:
  secretName: intermediate-ca-key-pair
  duration: 43800h # 5 years
  renewBefore: 720h # 30 days
  isCA: true
  commonName: intermediate-ca
  issuerRef:
    name: intermediate-ca
    kind: Issuer
## Optional intermediate CA END ##
---
## Issuer/CA for Kafka stuff ##
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: kafka-issuer
  namespace: streaming-pipeline
spec:
  ca:
    secretName: intermediate-ca-key-pair
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: kafka-broker-cert
  namespace: streaming-pipeline
spec:
  secretName: kafka-broker-tls
  commonName: kafka-broker.streaming-pipeline.svc.cluster.local
  dnsNames:
    - kafka-broker.streaming-pipeline.svc.cluster.local
    - kafka-0 # hostname for broker 0
    - kafka-1 # hostname for broker 1
    - kafka-2 # hostname for broker 2
    - kafka-0.kafka-broker
    - kafka-0.kafka-broker.streaming-pipeline.svc.cluster.local
    - kafka-1.kafka-broker
    - kafka-1.kafka-broker.streaming-pipeline.svc.cluster.local
    - kafka-2.kafka-broker
    - kafka-2.kafka-broker.streaming-pipeline.svc.cluster.local
    - "*.kafka-broker.streaming-pipeline.svc.cluster.local"
  issuerRef:
    name: kafka-issuer
    kind: Issuer
  usages:
    - server auth
    - client auth
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: zookeeper-cert
  namespace: streaming-pipeline
spec:
  secretName: zookeeper-tls
  commonName: zookeeper.streaming-pipeline.svc.cluster.local
  dnsNames:
    - zookeeper.streaming-pipeline.svc.cluster.local
  issuerRef:
    name: kafka-issuer
    kind: Issuer
  usages:
    - server auth
    - client auth
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  namespace: streaming-pipeline
spec:
  ports:
    - port: 2181
      targetPort: 2181
  clusterIP: None
  selector:
    app: zookeeper
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
  namespace: streaming-pipeline
spec:
  serviceName: "zookeeper"
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      # initContainers:
      #   - name: setup-keystore
      #     image: openjdk:11-jre
      #     command: ["sh", "-c"]
      #     args:
      #       - |
      #         # Convert PEM to PKCS12 for keystore
      #         openssl pkcs12 -export \
      #           -in /etc/certs/tls.crt \
      #           -inkey /etc/certs/tls.key \
      #           -out /tmp/zookeeper.p12 \
      #           -name zookeeper \
      #           -password pass:$PASSWORD;

      #         # Create the keystore
      #         keytool -importkeystore \
      #           -deststorepass $PASSWORD \
      #           -destkeypass $PASSWORD \
      #           -destkeystore /etc/zookeeper/secrets/jks/tls.keystore.jks \
      #           -srckeystore /tmp/zookeeper.p12 \
      #           -srcstoretype PKCS12 \
      #           -srcstorepass $PASSWORD \
      #           -alias zookeeper;

      #         # Import CA into truststore
      #         keytool -import \
      #           -trustcacerts \
      #           -file /etc/certs/ca.crt \
      #           -alias ca \
      #           -keystore /etc/zookeeper/secrets/jks/tls.truststore.jks \
      #           -storepass $PASSWORD -noprompt;
      #     env:
      #       - name: PASSWORD
      #         value: "changeit" # Replace with a secure password
      #     volumeMounts:
      #       - name: secrets-volume
      #         mountPath: /etc/zookeeper/secrets/jks
      #       - name: zookeeper-tls
      #         mountPath: /etc/certs
      containers:
        - name: zookeeper
          image: confluentinc/cp-zookeeper:latest
          ports:
            - containerPort: 2181
              name: client-port
            # - containerPort: 2888
            #   name: election-port
            # - containerPort: 3888
            #   name: leader-election # Port for leader election
            # - containerPort: 2281
            #   name: secure-client # Secure port for mTLS
          volumeMounts:
            - name: secrets-volume
              mountPath: /etc/zookeeper/secrets/jks
              readOnly: true
            - name: zookeeper-tls
              mountPath: /etc/zookeeper/secrets/certs
              readOnly: true
          env:
            # - name: ZOOKEEPER_SSL_CLIENT_AUTH
            #   value: "need"
            # - name: ZOOKEEPER_SSL_KEYSTORE_LOCATION
            #   value: "/etc/zookeeper/secrets/jks/tls.keystore.jks"
            # - name: ZOOKEEPER_SSL_TRUSTSTORE_LOCATION
            #   value: "/etc/zookeeper/secrets/jks/tls.truststore.jks"
            # - name: ZOOKEEPER_SSL_KEYSTORE_PASSWORD
            #   value: "changeit"
            # - name: ZOOKEEPER_SSL_TRUSTSTORE_PASSWORD
            #   value: "changeit"
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"  # Regular client port
            # - name: ZOOKEEPER_SECURE_CLIENT_PORT
            #   value: "2281"  # Secure client port for mTLS
      volumes:
        - name: zookeeper-tls
          secret:
            secretName: zookeeper-tls
        - name: secrets-volume
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-broker
  namespace: streaming-pipeline
spec:
  clusterIP: None
  ports:
    - port: 9092
      name: internal
    - port: 9093
      name: external
  selector:
    app: kafka
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: streaming-pipeline
spec:
  serviceName: kafka-broker
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      initContainers:
        - name: setup-keystore
          image: openjdk:11-jre
          command: ["sh", "-c"]
          args:
            - |
              # Convert PEM to PKCS12 for keystore
              openssl pkcs12 -export \
                -in /etc/certs/tls.crt \
                -inkey /etc/certs/tls.key \
                -out /tmp/kafka-broker.p12 \
                -name kafka-broker \
                -password pass:$PASSWORD;

              # Create the keystore
              keytool -importkeystore \
                -deststorepass $PASSWORD \
                -destkeypass $PASSWORD \
                -destkeystore /etc/kafka/secrets/jks/tls.keystore.jks \
                -srckeystore /tmp/kafka-broker.p12 \
                -srcstoretype PKCS12 \
                -srcstorepass $PASSWORD \
                -alias kafka-broker;

              # Import CA into truststore
              keytool -import \
                -trustcacerts \
                -file /etc/certs/ca.crt \
                -alias ca \
                -keystore /etc/kafka/secrets/jks/tls.truststore.jks \
                -storepass $PASSWORD -noprompt;
          env:
            - name: PASSWORD
              value: "changeit" # Replace with a secure password
          volumeMounts:
            - name: secrets-volume
              mountPath: /etc/kafka/secrets/jks
            - name: broker-tls
              mountPath: /etc/certs
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.4.0
          ports:
          - containerPort: 9092
            name: internal
          - containerPort: 9093
            name: external
          volumeMounts:
            - name: secrets-volume
              mountPath: /etc/kafka/secrets/jks
              readOnly: true
            - name: broker-tls
              mountPath: /etc/kafka/secrets/certs
              readOnly: true
          env:
            - name: KAFKA_BROKER_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.labels['apps.kubernetes.io/pod-index']
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "zookeeper.streaming-pipeline.svc.cluster.local:2181" # TODO. Use 2281 for SSL
            - name: KAFKA_LISTENERS
              value: "INTERNAL://:9092,EXTERNAL://:9093"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "INTERNAL://kafka-$(KAFKA_BROKER_ID).kafka-broker.streaming-pipeline.svc.cluster.local:9092,EXTERNAL://kafka-$(KAFKA_BROKER_ID).kafka-broker.streaming-pipeline.svc.cluster.local:9093"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:SSL,EXTERNAL:SSL"
            - name: KAFKA_SSL_CLIENT_AUTH
              value: "required"
            - name: KAFKA_SSL_KEYSTORE_LOCATION
              value: "/etc/kafka/secrets/jks/tls.keystore.jks"
            - name: KAFKA_SSL_KEYSTORE_FILENAME # Required by confluent image
              value: "jks/tls.keystore.jks"
            - name: KAFKA_SSL_KEYSTORE_PASSWORD
              value: "changeit" # Replace with a secure password
            - name: KAFKA_SSL_KEY_CREDENTIALS # Required by confluent image (possibly)
              value: "certs/tls.key"
            - name: KAFKA_SSL_KEYSTORE_CREDENTIALS # Required by confluent image (possibly)
              value: "certs/tls.key"
            - name: KAFKA_SSL_TRUSTSTORE_LOCATION
              value: "/etc/kafka/secrets/jks/tls.truststore.jks"
            - name: KAFKA_SSL_TRUSTSTORE_FILENAME # Required by confluent image
              value: "jks/tls.truststore.jks"
            - name: KAFKA_SSL_TRUSTSTORE_CREDENTIALS # Required by confluent image (possibly)
              value: "certs/tls.key"
            - name: KAFKA_SSL_TRUSTSTORE_PASSWORD
              value: "changeit" # Replace with a secure password
      volumes:
        - name: broker-tls
          secret:
            secretName: kafka-broker-tls
        - name: secrets-volume
          emptyDir: {}
# ---
# apiVersion: cert-manager.io/v1
# kind: Certificate
# metadata:
#   name: producer-cert
#   namespace: streaming-pipeline
# spec:
#   secretName: producer-tls
#   # duration: 24h
#   # renewBefore: 12h
#   isCA: false
#   # privateKey:
#   #   algorithm: RSA
#   #   size: 2048
#   usages:
#     - digital signature
#     - key encipherment
#     - client auth
#   commonName: producer.streaming-pipeline.svc.cluster.local
#   dnsNames:
#     - producer.streaming-pipeline.svc.cluster.local
#   issuerRef:
#     name: selfsigned-issuer
#     kind: Issuer
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: producer-cert
  namespace: streaming-pipeline
spec:
  secretName: producer-tls
  commonName: producer.streaming-pipeline.svc.cluster.local
  dnsNames:
    - producer.streaming-pipeline.svc.cluster.local
  issuerRef:
    name: kafka-issuer
    kind: Issuer
  usages:
    - server auth
    - client auth
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: consumer-cert
  namespace: streaming-pipeline
spec:
  secretName: consumer-tls
  duration: 24h
  renewBefore: 12h
  isCA: false
  privateKey:
    algorithm: RSA
    size: 2048
  usages:
    - digital signature
    - key encipherment
    - client auth
  dnsNames:
    - consumer.streaming-pipeline.svc.cluster.local
  issuerRef:
    name: kafka-issuer
    kind: Issuer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-producer
  namespace: streaming-pipeline
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-producer
  template:
    metadata:
      labels:
        app: kafka-producer
    spec:
      initContainers:
        - name: setup-keystore
          image: openjdk:11-jre
          command: ["sh", "-c"]
          args:
            - |
              # Echo info for debugging:
              ls -la /etc/certs/*

              # Convert PEM to PKCS12 for keystore
              openssl pkcs12 -export \
                -in /etc/certs/tls.crt \
                -inkey /etc/certs/tls.key \
                -out /tmp/kafka-client.p12 \
                -name kafka-client \
                -password pass:$PASSWORD;

              # Create the keystore
              keytool -importkeystore \
                -deststorepass $PASSWORD \
                -destkeypass $PASSWORD \
                -destkeystore /etc/kafka/secrets/jks/tls.keystore.jks \
                -srckeystore /tmp/kafka-client.p12 \
                -srcstoretype PKCS12 \
                -srcstorepass $PASSWORD \
                -alias kafka-client;

              # Import CA into truststore
              keytool -import \
                -trustcacerts \
                -file /etc/certs/ca.crt \
                -alias ca \
                -keystore /etc/kafka/secrets/jks/tls.truststore.jks \
                -storepass $PASSWORD -noprompt;
          env:
            - name: PASSWORD
              value: "changeit" # Replace with a secure password
          volumeMounts:
            - name: secrets-volume
              mountPath: /etc/kafka/secrets/jks
            - name: client-tls
              mountPath: /etc/certs
      containers:
        - name: producer
          image: confluentinc/cp-kafka:7.4.0
          # command: [ "/bin/bash", "-c", "--" ]
          # args: [ "while true; do sleep 30; done;" ]
          command:
            - /bin/bash
            - -c
            - |
              echo "Starting Kafka Producer..."
              kafka-console-producer \
                --broker-list kafka-broker.streaming-pipeline.svc.cluster.local:9093 \
                --producer.config /etc/producer-config/producer.properties \
                --topic demo-topic < /var/producer/producer.demo
          # kafka-console-producer --broker-list kafka-broker.streaming-pipeline.svc.cluster.local:9093 --producer.config /etc/producer-config/producer.properties --topic my-topic
          volumeMounts:
            - name: producer-config
              mountPath: /etc/producer-config
            - name: secrets-volume
              mountPath: /etc/jks
              readOnly: true
            - name: demo-data
              mountPath: /var/producer
      volumes:
        - name: producer-config
          configMap:
            name: producer-config
        - name: client-tls
          secret:
            secretName: producer-tls
        - name: secrets-volume
          emptyDir: {}
        - name: demo-data #TODO. remove when done. Used to validate producer
          configMap:
            name: producer-demo-data
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: producer-config
  namespace: streaming-pipeline
data:
  producer.properties: |
    security.protocol=SSL
    ssl.truststore.location=/etc/jks/tls.truststore.jks
    ssl.truststore.password=changeit
    ssl.keystore.location=/etc/jks/tls.keystore.jks
    ssl.keystore.password=changeit
    ssl.key.password=changeit
    ssl.keystore.type=PKCS12
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: producer-demo-data
  namespace: streaming-pipeline
data:
  producer.demo: |
    First message
    Second message
    And the third message
    Some other message which can be a long string of words that form a long sentence.
    Final message
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-consumer
  namespace: streaming-pipeline
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-consumer
  template:
    metadata:
      labels:
        app: kafka-consumer
    spec:
      initContainers:
        - name: setup-keystore
          image: openjdk:11-jre
          command: ["sh", "-c"]
          args:
            - |
              # Echo info for debugging:
              ls -la /etc/certs/*

              # Convert PEM to PKCS12 for keystore
              openssl pkcs12 -export \
                -in /etc/certs/tls.crt \
                -inkey /etc/certs/tls.key \
                -out /tmp/kafka-client.p12 \
                -name kafka-client \
                -password pass:$PASSWORD;

              # Create the keystore
              keytool -importkeystore \
                -deststorepass $PASSWORD \
                -destkeypass $PASSWORD \
                -destkeystore /etc/kafka/secrets/jks/tls.keystore.jks \
                -srckeystore /tmp/kafka-client.p12 \
                -srcstoretype PKCS12 \
                -srcstorepass $PASSWORD \
                -alias kafka-client;

              # Import CA into truststore
              keytool -import \
                -trustcacerts \
                -file /etc/certs/ca.crt \
                -alias ca \
                -keystore /etc/kafka/secrets/jks/tls.truststore.jks \
                -storepass $PASSWORD -noprompt;
          env:
            - name: PASSWORD
              value: "changeit" # Replace with a secure password
          volumeMounts:
            - name: secrets-volume
              mountPath: /etc/kafka/secrets/jks
            - name: client-tls
              mountPath: /etc/certs
      containers:
        - name: consumer
          image: confluentinc/cp-kafka:7.4.0
          command:
            - /bin/bash
            - -c
            - |
              echo "Starting Kafka Consumer..."
              kafka-console-consumer \
                --bootstrap-server kafka-broker.streaming-pipeline.svc.cluster.local:9093 \
                --consumer.config /etc/consumer-config/consumer.properties \
                --topic demo-topic \
                --from-beginning
          volumeMounts:
            - name: consumer-config
              mountPath: /etc/consumer-config
            - name: secrets-volume
              mountPath: /etc/jks
              readOnly: true
      volumes:
        - name: consumer-config
          configMap:
            name: consumer-config
        - name: client-tls
          secret:
            secretName: consumer-tls
        - name: secrets-volume
          emptyDir: {}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: consumer-config
  namespace: streaming-pipeline
data:
  consumer.properties: |
    security.protocol=SSL
    ssl.truststore.location=/etc/jks/tls.truststore.jks
    ssl.truststore.password=changeit
    ssl.keystore.location=/etc/jks/tls.keystore.jks
    ssl.keystore.password=changeit
    ssl.key.password=changeit
    ssl.keystore.type=PKCS12

# apiVersion: cert-manager.io/v1
# kind: Certificate
# metadata:
#   name: kafka-producer-cert
#   namespace: streaming-pipeline
# spec:
#   secretName: kafka-producer-tls
#   commonName: kafka-producer.streaming-pipeline.svc.cluster.local
#   dnsNames:
#     - kafka-producer.streaming-pipeline.svc.cluster.local
#   issuerRef:
#     name: selfsigned-issuer
#     kind: ClusterIssuer
#   usages:
#     - client auth
# ---
# apiVersion: cert-manager.io/v1
# kind: Certificate
# metadata:
#   name: kafka-consumer-cert
#   namespace: streaming-pipeline
# spec:
#   secretName: kafka-consumer-tls
#   commonName: kafka-consumer.streaming-pipeline.svc.cluster.local
#   dnsNames:
#     - kafka-consumer.streaming-pipeline.svc.cluster.local
#   issuerRef:
#     name: selfsigned-issuer
#     kind: ClusterIssuer
#   usages:
#     - client auth
# ---
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: kafka-producer
#   namespace: streaming-pipeline
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: kafka-producer
#   template:
#     metadata:
#       labels:
#         app: kafka-producer
#     spec:
#       containers:
#         - name: producer
#           image: confluentinc/cp-kafka:7.4.0
#           command: ["sh", "-c"]
#           args:
#             - |
#               /usr/bin/kafka-console-producer \
#               --broker-list kafka-broker.streaming-pipeline.svc.cluster.local:9093 \
#               --producer.config /etc/kafka/secrets/producer.properties \
#               --topic test
#           volumeMounts:
#             - name: producer-tls
#               mountPath: /etc/kafka/secrets
#               readOnly: true
#       volumes:
#         - name: producer-tls
#           secret:
#             secretName: kafka-producer-tls
# ---
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: kafka-consumer
#   namespace: streaming-pipeline
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: kafka-consumer
#   template:
#     metadata:
#       labels:
#         app: kafka-consumer
#     spec:
#       containers:
#         - name: consumer
#           image: confluentinc/cp-kafka:7.4.0
#           command: ["sh", "-c"]
#           args:
#             - |
#               /usr/bin/kafka-console-consumer \
#               --bootstrap-server kafka-broker.streaming-pipeline.svc.cluster.local:9093 \
#               --consumer.config /etc/kafka/secrets/consumer.properties \
#               --topic test
#           volumeMounts:
#             - name: consumer-tls
#               mountPath: /etc/kafka/secrets
#               readOnly: true
#       volumes:
#         - name: consumer-tls
#           secret:
#             secretName: kafka-consumer-tls

